1
00:00:00,000 --> 00:00:03,839
我們接下來要講Dify上面很重要的一個功能RAG

2
00:00:03,839 --> 00:00:05,919
RAG就是這三個字組成

3
00:00:05,919 --> 00:00:08,519
它的中文是檢索增強生成

4
00:00:08,519 --> 00:00:11,359
其實它是AI裡面很重要的一個能力

5
00:00:11,359 --> 00:00:13,279
有了這個RAG

6
00:00:13,279 --> 00:00:15,400
我們可以讓AI減少很多問題

7
00:00:15,400 --> 00:00:17,920
比如說像它知識過時的問題

8
00:00:17,920 --> 00:00:20,679
因為像大語言模型都要先預訓練

9
00:00:20,679 --> 00:00:23,320
但是當它的預訓練時間結束之後

10
00:00:23,320 --> 00:00:25,079
後面新的知識它就沒有

11
00:00:25,079 --> 00:00:28,039
另外就是說它會容易產生幻覺

12
00:00:28,039 --> 00:00:31,359
當它沒有的資料,它可能也會隨便掰個給你

13
00:00:31,359 --> 00:00:35,979
所以在RAG就是想辦法提供它有效的資料

14
00:00:35,979 --> 00:00:39,039
讓它生成的資料是從這些資料裡面產生的

15
00:00:39,039 --> 00:00:40,840
它就不會有幻覺的問題

16
00:00:40,840 --> 00:00:43,659
另外還有一些像私有的數據

17
00:00:43,659 --> 00:00:46,219
比如說公司有一些重要的文件

18
00:00:46,219 --> 00:00:48,520
這個重要的文件它沒有學過

19
00:00:48,520 --> 00:00:49,799
那要怎麼讓它知道?

20
00:00:49,799 --> 00:00:51,340
就是要透過RAG

21
00:00:51,340 --> 00:00:55,679
讓它去查到內容,然後來去提供給大語言模型

22
00:00:55,679 --> 00:00:59,280
這樣大語言模型第一個,它又回答得比較準確

23
00:00:59,280 --> 00:01:02,697
再來就是說它有一些沒讀過的資料你可以

24
00:01:02,697 --> 00:01:06,493
透過RAG的方式餵給它這下面就是RAG的

25
00:01:06,493 --> 00:01:09,531
三個步驟第一個部分它其實就是在檢索

26
00:01:09,531 --> 00:01:11,932
檢索它其實又分兩個階段

27
00:01:11,932 --> 00:01:15,891
前一個階段它其實就是在做ETL的工作

28
00:01:15,891 --> 00:01:17,891
就是把文的資料去做裁解

29
00:01:17,891 --> 00:01:20,691
然後向量化,最後存到向量資料庫

30
00:01:20,691 --> 00:01:23,572
再來就是我們要去詢問它的時候

31
00:01:23,572 --> 00:01:26,691
它會把這個問題去向量資料庫

32
00:01:26,691 --> 00:01:28,371
把文件的片段抓出來

33
00:01:28,371 --> 00:01:31,951
最後再把這個資料丟給大語言模型

34
00:01:31,951 --> 00:01:34,852
增加這個大語言模型的參考資料

35
00:01:34,852 --> 00:01:37,591
最後再生成我們需要的資訊

36
00:01:37,591 --> 00:01:40,012
所以RAG其實就這三個階段

37
00:01:40,012 --> 00:01:42,311
最重要的就是在前面檢索

38
00:01:42,311 --> 00:01:43,391
檢索這個部分

39
00:01:43,391 --> 00:01:45,852
它其實我們必須要準備好資料

40
00:01:45,852 --> 00:01:47,132
然後去做向量化

41
00:01:47,132 --> 00:01:50,652
這個東西就會牽扯到一些特別的模型

42
00:01:50,652 --> 00:01:52,492
還有一些特別的處理方式

43
00:01:52,492 --> 00:01:54,391
這個部分在Dify上面

44
00:01:54,391 --> 00:01:55,992
它有很方便的工具

45
00:01:55,992 --> 00:01:59,191
我們可以很簡單的把這個部分去做設定

46
00:01:59,191 --> 00:02:01,272
就可以把我們的資料當成知識庫

47
00:02:01,272 --> 00:02:02,871
所以在Dify上面

48
00:02:02,871 --> 00:02:05,909
它就直接稱這個功能叫做知識庫其實就是在

49
00:02:05,909 --> 00:02:08,947
做RAG的應用在這個上面圖我們可以看到

50
00:02:08,947 --> 00:02:12,464
有兩個重要的東西一個叫做Embedding

51
00:02:12,464 --> 00:02:15,663
Embedding其實就是整個RAG的核心

52
00:02:15,663 --> 00:02:18,350
它會把我們的文件去做向量化,

53
00:02:18,350 --> 00:02:20,463
然後再把它放到向量資料庫

54
00:02:20,463 --> 00:02:23,062
我們之後可以透過模糊的查詢

55
00:02:23,062 --> 00:02:24,463
來去查到相關資料

56
00:02:24,463 --> 00:02:27,281
另外還有一個叫做Rerank,

57
00:02:27,281 --> 00:02:30,663
Rerank其實是很多的系統沒有的功能

58
00:02:30,663 --> 00:02:33,984
模型一直都有,但是很多系統沒有做到這一塊

59
00:02:33,984 --> 00:02:36,104
像Google最近也有出RAG的功能

60
00:02:36,104 --> 00:02:38,503
但是它就只有單純的做向量化

61
00:02:38,503 --> 00:02:44,183
向量化通常分數頂多可以到80分就算很高了

62
00:02:44,183 --> 00:02:46,783
就是它命中率大概到八成就很高

63
00:02:46,783 --> 00:02:49,943
但是如果我們再透過Rerank

64
00:02:49,943 --> 00:02:51,870
這樣子排列出來的資料

65
00:02:51,870 --> 00:02:54,183
其實通常Docker以達到九成以上

66
00:02:54,183 --> 00:02:56,864
再加上這個Rerank的技術以後

67
00:02:56,864 --> 00:03:00,063
其實我們要拿到的資料準確性就會高非常多

68
00:03:00,063 --> 00:03:01,987
另外在大語言模型還有一個

69
00:03:01,987 --> 00:03:03,563
很重要的技術叫做微調

70
00:03:03,563 --> 00:03:04,563
Fine-tuning

71
00:03:04,563 --> 00:03:08,779
其實很多時候會把RAG跟Fine-tuning

72
00:03:08,779 --> 00:03:11,345
來做一個比較不過我目前是覺得

73
00:03:11,345 --> 00:03:14,828
基本上大部分的人都會用RAG來先做處理

74
00:03:14,828 --> 00:03:18,496
Fine-tuning的機會現在是越來越少

75
00:03:18,496 --> 00:03:20,895
為什麼?因為其實現在大語言模型

76
00:03:20,895 --> 00:03:23,195
它其實出的速度太快了

77
00:03:23,195 --> 00:03:25,295
每個新的模型出來以後

78
00:03:25,295 --> 00:03:29,795
它的能力就基本上是把前面的模型幹掉

79
00:03:29,795 --> 00:03:32,496
所以當你Fine-tuning完了以後

80
00:03:32,496 --> 00:03:34,496
它可能已經有新的模型出來

81
00:03:34,496 --> 00:03:37,975
就要再另外花時間在Fine-tuning新的模型

82
00:03:37,975 --> 00:03:41,295
不然你的新模型其實還是沒有你的資料

83
00:03:41,295 --> 00:03:43,315
所以微調這個部分其實

84
00:03:43,315 --> 00:03:45,336
現在做的人其實越來越少

85
00:03:45,336 --> 00:03:46,791
除非你真的是專門的技術

86
00:03:46,791 --> 00:03:48,776
來去做這個Fine-tuning

87
00:03:48,776 --> 00:03:50,767
所以目前其實大部分都會

88
00:03:50,767 --> 00:03:52,216
直接先用RAG來做

89
00:03:52,216 --> 00:03:53,575
因為這個速度最快

90
00:03:53,575 --> 00:03:56,256
可以因應不同的模型

91
00:03:56,256 --> 00:03:59,256
或者是說它新的模型推出速度很快

92
00:03:59,256 --> 00:04:01,496
你可以馬上就去套用新的RAG

93
00:04:01,496 --> 00:04:03,495
因為RAG你做一次就

94
00:04:03,495 --> 00:04:05,895
可以在不同的模型上去做使用

95
00:04:05,895 --> 00:04:08,975
這邊我們就會有三個階段

96
00:04:08,975 --> 00:04:10,536
檢索、增強、生成

97
00:04:10,536 --> 00:04:13,135
我們接下來就會講一下我們怎麼樣在Dify

98
00:04:13,135 --> 00:04:16,576
去設定我們的知識庫跟來使用它
